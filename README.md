Proyecto Final de Data Mining: PredicciÃ³n de LTV, CAC y ROMI para Showz

ğŸ“– Contexto

En el PSetÂ #4 se analizÃ³ mÃ©tricas histÃ³ricas de visitas, ventas y costos de Showz. Se construyeron modelos predictivos que estimen:

Lifetime Value (LTV) a 6â€“12 meses de cada cliente nuevo.

Customer Acquisition Cost (CAC) esperado por fuente y cohorte para el prÃ³ximo trimestre.

Retorno sobre la inversiÃ³n en marketing (ROMI) para cada canal de adquisiciÃ³n.

Se integraron tÃ©cnicas de Machine Learning (regresiÃ³n lineal, Ridge, Random Forest, XGBoost, LightGBM, CatBoost, ensambladores, validaciÃ³n con TimeSeriesSplit, explicabilidad con SHAP/PDP) y se generÃ³ una estrategia de asignaciÃ³n de presupuesto basada en simulaciones de ROMI.

ğŸ¯ Objetivos

Predecir el LTV de cada cliente nuevo en un horizonte de 6â€“12 meses.

Estimar el CAC por fuente y cohorte para el prÃ³ximo trimestre.

Identificar los drivers clave de LTV y CAC (explicabilidad).

Proponer una estrategia de asignaciÃ³n de presupuesto utilizando predicciones de ROMI.

ğŸ“‚ Estructura del repositorio

â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                # Datos originales (visits, orders, costs)
â”‚   â”œ-â”€ processed/          # CSVs limpios para modeling
â”œâ”€â”€ src/                    # CÃ³digo fuente
â”‚   â”œâ”€â”€ utils.py            # Funciones de carga, guardado y logging
â”‚   â”œâ”€â”€ features.py         # IngenierÃ­a de caracterÃ­sticas
â”‚   â””â”€â”€ train.py            # Script de entrenamiento y evaluaciÃ³n
â”œâ”€â”€ models/                 # Modelos entrenados (.pkl) y artefactos
â”œâ”€â”€ notebooks/              # Notebooks de EDA, FE y resultados finales
    â”œâ”€â”€ 01_EDA.ipynb 
    â”œâ”€â”€ 02_FeatureEngineering.ipynb
    â”œâ”€â”€ 03_ModelTraining.ipynb 
    â”œâ”€â”€ 04_explicabilidad_Diagnostico.ipynb
    â””â”€â”€ Final_Project_Showz_LTV_CAC.ipynb
â”œâ”€â”€ requirements.txt        # Dependencias Python
â””â”€â”€ README.md               # DocumentaciÃ³n general

ğŸ› ï¸ Requisitos

PythonÂ 3.8+

pip

requirements.txt contiene:

pandas
numpy
scikit-learn
xgboost
lightgbm
catboost
shap
pyyaml
joblib

ğŸš€ InstalaciÃ³n

# Clona este repositorio
git clone https://github.com/maemiliarv/DataMiningProyectoFinal.git
cd DataMiningProyectoFinal

# Crea y activa virtualenv (opcional)
python -m venv venv
source venv/bin/activate  # Linux/MacOSenv\Scripts\activate  # Windows

# Instala dependencias
pip install -r requirements.txt

âš™ï¸ ConfiguraciÃ³n

Edita configs/config.yaml para ajustar rutas y parÃ¡metros:

data:
  input_path: data/processed/modeling_dataset.csv
  features:
    - revenue
    - costs
    - session_duration
    # ...otras features generadas
  target: LTV_180
  test_size: 0.2
  random_state: 42
model:
  output_path: models/LTV_180/final_model.pkl
  params:
    n_estimators: 100
    max_depth: 10
logging:
  file: logs/train.log

â–¶ï¸ EjecuciÃ³n

# Entrena el modelo de LTV
env/bin/python src/train.py --config configs/config.yaml

Los logs aparecerÃ¡n en consola y en el archivo logs/train.log.

El modelo final se guardarÃ¡ en models/LTV_180/final_model.pkl.

Para entrenar CAC o probar otro target, duplica el bloque data.target y model.output_path en tu YAML.

ğŸ“Š Resultados y EvaluaciÃ³n

MÃ©tricas: MAE, RMSE, MAPE sobre sets de validaciÃ³n temporal (TimeSeriesSplit) y test.

Explicabilidad: importancia de features (gain, permutation), SHAP/PDP para topÂ 5.

SimulaciÃ³n de ROMI: usa predicciones de LTV y CAC para cuantificar retorno por canal ante distintos escenarios de presupuesto.

Revisa notebooks/Final_Project_Showz_LTV_CAC.ipynb para visualizaciones y anÃ¡lisis detallado.

ğŸ” MetodologÃ­a

Este proyecto sigue el ciclo CRISPâ€‘DM:

Business Understanding

Data Understanding

Data Preparation (ingenierÃ­a avanzada de features)

Modeling (baseline, avanzados, ensambladores)

Evaluation & Selection (TimeSeriesSplit + GridSearchCV)

Deployment & Simulation (estrategia de marketing)
