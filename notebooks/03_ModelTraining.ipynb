{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55639cf5",
   "metadata": {},
   "source": [
    "Para esta sección vamos a hacer una funcion para cada modelo.\n",
    "\n",
    "Cada funcion de modelaje será hecha con GridSearchCV para la selección de hiperparametros. Se usará TimeSeriesSplit para la validación cruzada. Cada función nos devolverá el modelo entrenado con el resultado de las metricas MAE, RMSE y MAPE. Nos entregará un diccionario con estas métricas. Cada función también va a imprimir estas métricas. Cada función va a tomar 6 parametros. X_train, X_validation, X_test, y_train, y_validation, y_test.\n",
    "\n",
    "Habrá una función que divida el data set de la manera que se estipula en el pdf. Siendo esta train 2017, validation 1er sem 2018, test 2do sem 2018.\n",
    "\n",
    "Habrá una 'función maestra' que como parámetro solo tenga el df. Aquí se van a ejecutar todas las funciones. Primero dividiendo el dataset, y de ahí yendo en el siguiente orden: Regresiones (Lineal, Estocastica y Ridge), Modelos avanzados (Random Forest y Gradient Boosting (XGBoost, LightGBM y CatBoost)) y Ensamblador (stacking y blending). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "c7ab0459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "be3fa438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset\n",
    "df = pd.read_csv('../data/processed/modeling_dataset.csv')\n",
    "df['fecha_primera_sesion'] = pd.to_datetime(df['fecha_primera_sesion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "17cf9d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividiendo el dataset como se pide. Bueno esta hecho para 6 meses de 2017 y 2 trimestres de 2018\n",
    "def dividir_dataset(df, fecha_col='fecha_primera_sesion'):\n",
    "    df[fecha_col] = pd.to_datetime(df[fecha_col])\n",
    "    train = df[df[fecha_col].dt.year == 2017]\n",
    "    val = df[(df[fecha_col].dt.year == 2018) & (df[fecha_col].dt.month <= 3)]\n",
    "    test = df[(df[fecha_col].dt.year == 2018) & (df[fecha_col].dt.month > 3)]\n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "51f5a9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_df(X_like, ref_df):\n",
    "#  convierte ndarray -> DataFrame con los mismos nombres.\n",
    "    if isinstance(X_like, np.ndarray):\n",
    "        return pd.DataFrame(X_like, columns=ref_df.columns)\n",
    "    return X_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d3042b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metricas(y_true, y_pred):\n",
    "    mae  = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mape = np.mean(np.abs((y_true - y_pred)[y_true != 0] / y_true[y_true != 0])) * 100\n",
    "    return {\"MAE\": mae, \"RMSE\": rmse, \"MAPE\": mape}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "361815ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelo_con_gridsearch(modelo_base, param_grid,X_train, X_val, X_test, y_train, y_val, y_test, numeric_cols=None):\n",
    "    if numeric_cols is None:\n",
    "        numeric_cols = X_train.columns                \n",
    "    preproc = ColumnTransformer(\n",
    "        [(\"scale\", StandardScaler(), numeric_cols)],\n",
    "        remainder=\"drop\"\n",
    "    ).set_output(transform=\"pandas\")                  \n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        (\"pre\", preproc),\n",
    "        (\"modelo\", modelo_base)\n",
    "    ])\n",
    "\n",
    "    param_grid_pipeline = {f\"modelo__{k}\": v for k, v in param_grid.items()}\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    grid = GridSearchCV(\n",
    "        pipeline,\n",
    "        param_grid_pipeline,\n",
    "        cv=tscv,\n",
    "        scoring=\"neg_root_mean_squared_error\",\n",
    "        refit=True\n",
    "    )\n",
    "    grid.fit(X_train, y_train)\n",
    "    print(\"Mejores parámetros:\", grid.best_params_)\n",
    "\n",
    "    best_model = grid.best_estimator_          \n",
    "\n",
    "    # evaluación en validacion\n",
    "    y_pred_val = best_model.predict(to_df(X_val, X_train))\n",
    "    val_scores = metricas(y_val, y_pred_val)\n",
    "    print(f\"[VALIDACIÓN] MAE={val_scores['MAE']:.2f}, \"\n",
    "          f\"RMSE={val_scores['RMSE']:.2f}, MAPE={val_scores['MAPE']:.2f}%\")\n",
    "\n",
    "    # refit en train+val\n",
    "    X_train_val = pd.concat([X_train, X_val], axis=0)\n",
    "    y_train_val = pd.concat([y_train, y_val], axis=0)\n",
    "    best_model.fit(X_train_val, y_train_val)\n",
    "\n",
    "    # evaluación final en test\n",
    "    y_pred_test = best_model.predict(to_df(X_test, X_train))\n",
    "    test_scores = metricas(y_test, y_pred_test)\n",
    "    print(f\"[TEST] MAE={test_scores['MAE']:.2f}, \"\n",
    "          f\"RMSE={test_scores['RMSE']:.2f}, MAPE={test_scores['MAPE']:.2f}%\")\n",
    "\n",
    "    return best_model, {\"val\": val_scores, \"test\": test_scores}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c4a7430a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#regresion lineal\n",
    "def modelo_lineal(*args):\n",
    "    return modelo_con_gridsearch(LinearRegression(), {}, *args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "47b97867",
   "metadata": {},
   "outputs": [],
   "source": [
    "#estoacastico\n",
    "def modelo_estocastico(*args):\n",
    "    param_grid = {'alpha': [0.0001, 0.001, 0.01], 'penalty': ['l2', 'elasticnet']}\n",
    "    return modelo_con_gridsearch(SGDRegressor(max_iter=1000, tol=1e-3), param_grid, *args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "1756242d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ridge\n",
    "def modelo_ridge(*args):\n",
    "    param_grid = {'alpha': [0.1, 1.0, 10.0]}\n",
    "    return modelo_con_gridsearch(Ridge(), param_grid, *args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "18ff99bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest\n",
    "def modelo_rf(*args):\n",
    "    param_grid = {'n_estimators': [100, 200], 'max_depth': [3, 5, 10]}\n",
    "    return modelo_con_gridsearch(RandomForestRegressor(), param_grid, *args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "178f5564",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgboost\n",
    "def modelo_xgb(*args):\n",
    "    param_grid = {'n_estimators': [100], 'max_depth': [3, 5], 'learning_rate': [0.1]}\n",
    "    return modelo_con_gridsearch(XGBRegressor(verbosity=0), param_grid, *args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "df79d6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lightGBM\n",
    "def modelo_lgbm(*args):\n",
    "    param_grid = {'n_estimators': [100], 'max_depth': [3, 5], 'learning_rate': [0.1]}\n",
    "    #si algo se ve raro cambiar el verbose\n",
    "    return modelo_con_gridsearch(LGBMRegressor(verbose=-1), param_grid, *args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "1ea9fa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#catboost\n",
    "def modelo_catboost(*args):\n",
    "    param_grid = {'iterations': [100], 'depth': [3, 5], 'learning_rate': [0.1]}\n",
    "    #si algo se ve raro cambiar el verbose\n",
    "    return modelo_con_gridsearch(CatBoostRegressor(verbose=0), param_grid, *args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "0a937a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.base import clone\n",
    "import pandas as pd\n",
    "\n",
    "def ensamblador_stacking_gridsearch(\n",
    "    base_estimators: dict,\n",
    "    param_grids: dict,\n",
    "    final_estimator,\n",
    "    X_train, X_val, X_test,\n",
    "    y_train, y_val, y_test,\n",
    "    numeric_cols=None\n",
    "):\n",
    "\n",
    "    best_models = []\n",
    "\n",
    "    # Grid search por modelo base\n",
    "    for name, est in base_estimators.items():\n",
    "        print(f\"\\n====== Optimizando {name} ======\")\n",
    "        best_model, _ = modelo_con_gridsearch(\n",
    "            modelo_base=est,\n",
    "            param_grid=param_grids[name],\n",
    "            X_train=X_train, X_val=X_val, X_test=X_test,\n",
    "            y_train=y_train, y_val=y_val, y_test=y_test,\n",
    "            numeric_cols=numeric_cols\n",
    "        )\n",
    "        # clone() devuelve una copia *sin entrenar* apta para StackingRegressor\n",
    "        best_models.append((name, clone(best_model)))\n",
    "\n",
    "    # definir y entrenar el stacking\n",
    "    stacker = StackingRegressor(\n",
    "        estimators=best_models,\n",
    "        final_estimator=final_estimator,\n",
    "        n_jobs=-1,\n",
    "        passthrough=False        # solo usamos las predicciones, no las X originales\n",
    "    )\n",
    "\n",
    "    # train + val retrain\n",
    "    X_train_val = pd.concat([X_train, X_val])\n",
    "    y_train_val = pd.concat([y_train, y_val])\n",
    "    stacker.fit(X_train_val, y_train_val)\n",
    "\n",
    "    #evaluacion\n",
    "    y_pred_val  = stacker.predict(to_df(X_val,  X_train))\n",
    "    val_scores  = metricas(y_val,  y_pred_val)\n",
    "    print(f\"[STACKING VALIDACIÓN] MAE={val_scores['MAE']:.2f}, \"\n",
    "          f\"RMSE={val_scores['RMSE']:.2f}, MAPE={val_scores['MAPE']:.2f}%\")\n",
    "\n",
    "    y_pred_test = stacker.predict(to_df(X_test, X_train))\n",
    "    test_scores = metricas(y_test, y_pred_test)\n",
    "    print(f\"[STACKING TEST]       MAE={test_scores['MAE']:.2f}, \"\n",
    "          f\"RMSE={test_scores['RMSE']:.2f}, MAPE={test_scores['MAPE']:.2f}%\")\n",
    "\n",
    "    return stacker, {\"val\": val_scores, \"test\": test_scores}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "879671ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelo_stacking(X_train, X_val, X_test,\n",
    "                    y_train, y_val, y_test,\n",
    "                    numeric_cols=None):\n",
    "\n",
    "    base_estimators = {\n",
    "        \"ridge\": Ridge(),\n",
    "        \"rf\"   : RandomForestRegressor(random_state=42),\n",
    "        \"xgb\"  : XGBRegressor(verbosity=0, random_state=42)\n",
    "    }\n",
    "    param_grids = {\n",
    "        \"ridge\": {\"alpha\": [0.1, 1.0, 10]},\n",
    "        \"rf\"   : {\"n_estimators\": [100, 200],\n",
    "                  \"max_depth\"  : [3, 5, 10]},\n",
    "        \"xgb\"  : {\"n_estimators\"  : [200, 400],\n",
    "                  \"learning_rate\": [0.05, 0.1]}\n",
    "    }\n",
    "\n",
    "    stack_model, scores = ensamblador_stacking_gridsearch(\n",
    "        base_estimators=base_estimators,\n",
    "        param_grids=param_grids,\n",
    "        final_estimator=LinearRegression(),\n",
    "        X_train=X_train, X_val=X_val, X_test=X_test,\n",
    "        y_train=y_train, y_val=y_val, y_test=y_test,\n",
    "        numeric_cols=numeric_cols\n",
    "    )\n",
    "\n",
    "    return stack_model, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "d0544600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import clone\n",
    "from sklearn.linear_model import LinearRegression  # meta‑modelo por defecto\n",
    "\n",
    "def ensamblador_blending_gridsearch(\n",
    "    base_estimators: dict,\n",
    "    param_grids: dict,\n",
    "    final_estimator,\n",
    "    X_train, X_val, X_test,\n",
    "    y_train, y_val, y_test,\n",
    "    numeric_cols=None\n",
    "):\n",
    "\n",
    "    best_models = {}\n",
    "    val_meta_X  = [] \n",
    "    test_meta_X = []\n",
    "\n",
    "    # Grid search por modelo base\n",
    "    for name, est in base_estimators.items():\n",
    "        print(f\"\\n====== Optimizando {name} ======\")\n",
    "        best_model, _ = modelo_con_gridsearch(\n",
    "            modelo_base=est,\n",
    "            param_grid=param_grids[name],\n",
    "            X_train=X_train, X_val=X_val, X_test=X_test,\n",
    "            y_train=y_train, y_val=y_val, y_test=y_test,\n",
    "            numeric_cols=numeric_cols\n",
    "        )\n",
    "        best_models[name] = clone(best_model)\n",
    "\n",
    "    #entrenamiento\n",
    "    for name, mdl in best_models.items():\n",
    "        mdl.fit(to_df(X_train, X_train), y_train)          \n",
    "        val_meta_X.append(mdl.predict(to_df(X_val,  X_train)))\n",
    "    \n",
    "    val_meta_X = np.column_stack(val_meta_X)               \n",
    "\n",
    "    # entreno meta‑modelo con las preds de VAL\n",
    "    meta = clone(final_estimator)\n",
    "    meta.fit(val_meta_X, y_val)\n",
    "    \n",
    "    # train + val retrain\n",
    "    X_train_val = pd.concat([X_train, X_val])\n",
    "    y_train_val = pd.concat([y_train, y_val])\n",
    "\n",
    "    test_meta_X = []\n",
    "    for name, mdl in best_models.items():\n",
    "        mdl.fit(to_df(X_train_val, X_train), y_train_val)  # Train+Val\n",
    "        test_meta_X.append(mdl.predict(to_df(X_test, X_train)))\n",
    "\n",
    "    test_meta_X = np.column_stack(test_meta_X)\n",
    "    y_pred_test = meta.predict(test_meta_X)\n",
    "\n",
    "    # metricas\n",
    "    y_pred_val = meta.predict(val_meta_X)\n",
    "    val_scores  = metricas(y_val,  y_pred_val)\n",
    "    test_scores = metricas(y_test, y_pred_test)\n",
    "\n",
    "    print(f\"[BLENDING VALIDACIÓN] MAE={val_scores['MAE']:.2f}, \"\n",
    "          f\"RMSE={val_scores['RMSE']:.2f}, MAPE={val_scores['MAPE']:.2f}%\")\n",
    "    print(f\"[BLENDING TEST]       MAE={test_scores['MAE']:.2f}, \"\n",
    "          f\"RMSE={test_scores['RMSE']:.2f}, MAPE={test_scores['MAPE']:.2f}%\")\n",
    "\n",
    "    return meta, {\"val\": val_scores, \"test\": test_scores}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "1c5bb425",
   "metadata": {},
   "outputs": [],
   "source": [
    "#blending\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "def modelo_blending(X_train, X_val, X_test,\n",
    "                    y_train, y_val, y_test,\n",
    "                    numeric_cols=None):\n",
    "\n",
    "    base_estimators = {\n",
    "        \"ridge\": Ridge(),\n",
    "        \"rf\"   : RandomForestRegressor(random_state=42),\n",
    "        \"xgb\"  : XGBRegressor(verbosity=0, random_state=42)\n",
    "    }\n",
    "    param_grids = {\n",
    "        \"ridge\": {\"alpha\": [0.1, 1.0, 10]},\n",
    "        \"rf\"   : {\"n_estimators\": [100, 200],\n",
    "                  \"max_depth\"  : [3, 5, 10]},\n",
    "        \"xgb\"  : {\"n_estimators\"  : [200, 400],\n",
    "                  \"learning_rate\": [0.05, 0.1]}\n",
    "    }\n",
    "\n",
    "    blending_model, scores = ensamblador_blending_gridsearch(\n",
    "        base_estimators=base_estimators,\n",
    "        param_grids=param_grids,\n",
    "        final_estimator=LinearRegression(),\n",
    "        X_train=X_train, X_val=X_val, X_test=X_test,\n",
    "        y_train=y_train, y_val=y_val, y_test=y_test,\n",
    "        numeric_cols=numeric_cols\n",
    "    )\n",
    "    return blending_model, scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "985b909a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion principal para ejecutar los modelos\n",
    "def ejecutar_modelos(df, target_col, fecha_col='fecha_primera_sesion'):\n",
    "    # Definimos las columnas a excluir del modelado\n",
    "    columnas_excluir = [\n",
    "        target_col,\n",
    "        fecha_col,\n",
    "        'uid',\n",
    "        'fecha_primera_compra',\n",
    "        'fecha_ultima_compra',\n",
    "        'fecha_primera_sesion',\n",
    "    ]\n",
    "\n",
    "    # Eliminar las filas que tienen nulos en la columna objetivo\n",
    "    df = df.dropna(subset=[target_col])\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Dividimos el dataset por fecha\n",
    "    train, val, test = dividir_dataset(df, fecha_col)\n",
    "\n",
    "    # Separar X e y\n",
    "    X_train = train.drop(columns=columnas_excluir)\n",
    "    y_train = train[target_col]\n",
    "\n",
    "    X_val = val.drop(columns=columnas_excluir)\n",
    "    y_val = val[target_col]\n",
    "\n",
    "    X_test = test.drop(columns=columnas_excluir)\n",
    "    y_test = test[target_col]\n",
    "\n",
    "    modelos = {}\n",
    "    evaluaciones = {}\n",
    "\n",
    "    print(\"Modelos de regresión:\")\n",
    "    print('\\n\\nLineal\\n\\n')\n",
    "    modelos['lineal'], evaluaciones['lineal'] = modelo_lineal(X_train, X_val, X_test, y_train, y_val, y_test)\n",
    "    print('\\n\\nEstocastico\\n\\n')\n",
    "    modelos['estocastico'], evaluaciones['estocastico'] = modelo_estocastico(X_train, X_val, X_test, y_train, y_val, y_test)\n",
    "    print('\\n\\nRidge\\n\\n')\n",
    "    modelos['ridge'], evaluaciones['ridge'] = modelo_ridge(X_train, X_val, X_test, y_train, y_val, y_test)\n",
    "\n",
    "    print(\"\\n\\n\\nModelos avanzados:\")\n",
    "    print('\\n\\nRandom Forest\\n\\n')\n",
    "    modelos['rf'], evaluaciones['rf'] = modelo_rf(X_train, X_val, X_test, y_train, y_val, y_test)\n",
    "    print('\\n\\nXGBoost\\n\\n')\n",
    "    modelos['xgb'], evaluaciones['xgb'] = modelo_xgb(X_train, X_val, X_test, y_train, y_val, y_test)\n",
    "    print('\\n\\nLightGBM\\n\\n')\n",
    "    modelos['lgbm'], evaluaciones['lgbm'] = modelo_lgbm(X_train, X_val, X_test, y_train, y_val, y_test)\n",
    "    print('\\n\\nCatboost\\n\\n')\n",
    "    modelos['catboost'], evaluaciones['catboost'] = modelo_catboost(X_train, X_val, X_test, y_train, y_val, y_test)\n",
    "\n",
    "    print(\"\\n\\n\\nModelos ensambladores:\")\n",
    "    print('\\n\\nStacking\\n\\n')\n",
    "    modelos['stacking'], evaluaciones['stacking'] = modelo_stacking(X_train, X_val, X_test, y_train, y_val, y_test)\n",
    "    print('\\n\\nBlending\\n\\n')\n",
    "    modelos['blending'], evaluaciones['blending'] = modelo_blending(X_train, X_val, X_test, y_train, y_val, y_test)\n",
    "\n",
    "    return modelos, evaluaciones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9655aff",
   "metadata": {},
   "source": [
    "# Importación de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "8fd83b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "def guardar_modelos_y_resultados(modelos, evaluaciones, target_name):\n",
    "    # Crear carpeta si no existe\n",
    "    models_dir = f\"../models/{target_name}\"\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "    # Guardar modelos\n",
    "    for nombre, modelo in modelos.items():\n",
    "        ruta = os.path.join(models_dir, f\"{nombre}.pkl\")\n",
    "        with open(ruta, \"wb\") as f:\n",
    "            pickle.dump(modelo, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        print(f\"Modelo «{nombre}» guardado en {ruta}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "f5159582",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostrar_resultados(evaluaciones, target_name):\n",
    "    resultados_df = pd.DataFrame({\n",
    "        modelo: scores[\"test\"] for modelo, scores in evaluaciones.items()\n",
    "    }).T\n",
    "    resultados_df.index.name = f\"Modelos ({target_name})\"\n",
    "    display(resultados_df.sort_values('MAPE'))\n",
    "    return resultados_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f424968d",
   "metadata": {},
   "source": [
    "### Implementación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "0a479c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENTRENAMIENTO Y EVALUACION DE LTV\n",
      "Modelos de regresión:\n",
      "\n",
      "\n",
      "Lineal\n",
      "\n",
      "\n",
      "Mejores parámetros: {}\n",
      "[VALIDACIÓN] MAE=1.61, RMSE=4.49, MAPE=90.54%\n",
      "[TEST] MAE=0.85, RMSE=2.01, MAPE=48.76%\n",
      "\n",
      "\n",
      "Estocastico\n",
      "\n",
      "\n",
      "Mejores parámetros: {'modelo__alpha': 0.001, 'modelo__penalty': 'elasticnet'}\n",
      "[VALIDACIÓN] MAE=2926384.93, RMSE=7847405.34, MAPE=179832604.05%\n",
      "[TEST] MAE=109834538.70, RMSE=545851328.79, MAPE=5266888994.83%\n",
      "\n",
      "\n",
      "Ridge\n",
      "\n",
      "\n",
      "Mejores parámetros: {'modelo__alpha': 0.1}\n",
      "[VALIDACIÓN] MAE=1.61, RMSE=4.49, MAPE=90.55%\n",
      "[TEST] MAE=0.85, RMSE=2.01, MAPE=48.76%\n",
      "\n",
      "\n",
      "\n",
      "Modelos avanzados:\n",
      "\n",
      "\n",
      "Random Forest\n",
      "\n",
      "\n",
      "Mejores parámetros: {'modelo__max_depth': 5, 'modelo__n_estimators': 100}\n",
      "[VALIDACIÓN] MAE=0.76, RMSE=4.65, MAPE=58.58%\n",
      "[TEST] MAE=0.80, RMSE=3.67, MAPE=68.33%\n",
      "\n",
      "\n",
      "XGBoost\n",
      "\n",
      "\n",
      "Mejores parámetros: {'modelo__learning_rate': 0.1, 'modelo__max_depth': 3, 'modelo__n_estimators': 100}\n",
      "[VALIDACIÓN] MAE=0.68, RMSE=4.55, MAPE=39.49%\n",
      "[TEST] MAE=0.73, RMSE=6.55, MAPE=45.04%\n",
      "\n",
      "\n",
      "LightGBM\n",
      "\n",
      "\n",
      "Mejores parámetros: {'modelo__learning_rate': 0.1, 'modelo__max_depth': 5, 'modelo__n_estimators': 100}\n",
      "[VALIDACIÓN] MAE=1.06, RMSE=19.63, MAPE=17.60%\n",
      "[TEST] MAE=1.67, RMSE=22.23, MAPE=39.05%\n",
      "\n",
      "\n",
      "Catboost\n",
      "\n",
      "\n",
      "Mejores parámetros: {'modelo__depth': 5, 'modelo__iterations': 100, 'modelo__learning_rate': 0.1}\n",
      "[VALIDACIÓN] MAE=1.10, RMSE=7.89, MAPE=70.87%\n",
      "[TEST] MAE=1.12, RMSE=14.37, MAPE=57.78%\n",
      "\n",
      "\n",
      "\n",
      "Modelos ensambladores:\n",
      "\n",
      "\n",
      "Stacking\n",
      "\n",
      "\n",
      "\n",
      "====== Optimizando ridge ======\n",
      "Mejores parámetros: {'modelo__alpha': 0.1}\n",
      "[VALIDACIÓN] MAE=1.61, RMSE=4.49, MAPE=90.55%\n",
      "[TEST] MAE=0.85, RMSE=2.01, MAPE=48.76%\n",
      "\n",
      "====== Optimizando rf ======\n",
      "Mejores parámetros: {'modelo__max_depth': 10, 'modelo__n_estimators': 200}\n",
      "[VALIDACIÓN] MAE=0.13, RMSE=3.38, MAPE=1.23%\n",
      "[TEST] MAE=0.08, RMSE=2.61, MAPE=0.88%\n",
      "\n",
      "====== Optimizando xgb ======\n",
      "Mejores parámetros: {'modelo__learning_rate': 0.1, 'modelo__n_estimators': 200}\n",
      "[VALIDACIÓN] MAE=0.23, RMSE=4.05, MAPE=2.68%\n",
      "[TEST] MAE=0.32, RMSE=7.08, MAPE=2.40%\n",
      "[STACKING VALIDACIÓN] MAE=0.71, RMSE=3.68, MAPE=27.12%\n",
      "[STACKING TEST]       MAE=0.81, RMSE=1.89, MAPE=42.33%\n",
      "\n",
      "\n",
      "Blending\n",
      "\n",
      "\n",
      "\n",
      "====== Optimizando ridge ======\n",
      "Mejores parámetros: {'modelo__alpha': 0.1}\n",
      "[VALIDACIÓN] MAE=1.61, RMSE=4.49, MAPE=90.55%\n",
      "[TEST] MAE=0.85, RMSE=2.01, MAPE=48.76%\n",
      "\n",
      "====== Optimizando rf ======\n",
      "Mejores parámetros: {'modelo__max_depth': 10, 'modelo__n_estimators': 200}\n",
      "[VALIDACIÓN] MAE=0.13, RMSE=3.38, MAPE=1.23%\n",
      "[TEST] MAE=0.08, RMSE=2.61, MAPE=0.88%\n",
      "\n",
      "====== Optimizando xgb ======\n",
      "Mejores parámetros: {'modelo__learning_rate': 0.1, 'modelo__n_estimators': 200}\n",
      "[VALIDACIÓN] MAE=0.23, RMSE=4.05, MAPE=2.68%\n",
      "[TEST] MAE=0.32, RMSE=7.08, MAPE=2.40%\n",
      "[BLENDING VALIDACIÓN] MAE=0.40, RMSE=2.45, MAPE=14.46%\n",
      "[BLENDING TEST]       MAE=0.96, RMSE=3.18, MAPE=50.29%\n",
      "Modelo «lineal» guardado en ../models/LTV_180/lineal.pkl\n",
      "Modelo «estocastico» guardado en ../models/LTV_180/estocastico.pkl\n",
      "Modelo «ridge» guardado en ../models/LTV_180/ridge.pkl\n",
      "Modelo «rf» guardado en ../models/LTV_180/rf.pkl\n",
      "Modelo «xgb» guardado en ../models/LTV_180/xgb.pkl\n",
      "Modelo «lgbm» guardado en ../models/LTV_180/lgbm.pkl\n",
      "Modelo «catboost» guardado en ../models/LTV_180/catboost.pkl\n",
      "Modelo «stacking» guardado en ../models/LTV_180/stacking.pkl\n",
      "Modelo «blending» guardado en ../models/LTV_180/blending.pkl\n",
      "ENTRENAMIENTO Y EVALUACION DE CAC\n",
      "Modelos de regresión:\n",
      "\n",
      "\n",
      "Lineal\n",
      "\n",
      "\n",
      "Mejores parámetros: {}\n",
      "[VALIDACIÓN] MAE=0.12, RMSE=0.14, MAPE=41.25%\n",
      "[TEST] MAE=0.12, RMSE=0.14, MAPE=39.59%\n",
      "\n",
      "\n",
      "Estocastico\n",
      "\n",
      "\n",
      "Mejores parámetros: {'modelo__alpha': 0.01, 'modelo__penalty': 'elasticnet'}\n",
      "[VALIDACIÓN] MAE=0.12, RMSE=0.14, MAPE=40.74%\n",
      "[TEST] MAE=0.12, RMSE=0.14, MAPE=40.08%\n",
      "\n",
      "\n",
      "Ridge\n",
      "\n",
      "\n",
      "Mejores parámetros: {'modelo__alpha': 10.0}\n",
      "[VALIDACIÓN] MAE=0.12, RMSE=0.14, MAPE=41.25%\n",
      "[TEST] MAE=0.12, RMSE=0.14, MAPE=39.59%\n",
      "\n",
      "\n",
      "\n",
      "Modelos avanzados:\n",
      "\n",
      "\n",
      "Random Forest\n",
      "\n",
      "\n",
      "Mejores parámetros: {'modelo__max_depth': 10, 'modelo__n_estimators': 100}\n",
      "[VALIDACIÓN] MAE=0.00, RMSE=0.00, MAPE=0.00%\n",
      "[TEST] MAE=0.00, RMSE=0.00, MAPE=0.00%\n",
      "\n",
      "\n",
      "XGBoost\n",
      "\n",
      "\n",
      "Mejores parámetros: {'modelo__learning_rate': 0.1, 'modelo__max_depth': 3, 'modelo__n_estimators': 100}\n",
      "[VALIDACIÓN] MAE=0.00, RMSE=0.00, MAPE=0.00%\n",
      "[TEST] MAE=0.00, RMSE=0.00, MAPE=0.00%\n",
      "\n",
      "\n",
      "LightGBM\n",
      "\n",
      "\n",
      "Mejores parámetros: {'modelo__learning_rate': 0.1, 'modelo__max_depth': 3, 'modelo__n_estimators': 100}\n",
      "[VALIDACIÓN] MAE=0.00, RMSE=0.00, MAPE=0.00%\n",
      "[TEST] MAE=0.00, RMSE=0.00, MAPE=0.00%\n",
      "\n",
      "\n",
      "Catboost\n",
      "\n",
      "\n",
      "Mejores parámetros: {'modelo__depth': 3, 'modelo__iterations': 100, 'modelo__learning_rate': 0.1}\n",
      "[VALIDACIÓN] MAE=0.00, RMSE=0.00, MAPE=0.13%\n",
      "[TEST] MAE=0.00, RMSE=0.00, MAPE=0.11%\n",
      "\n",
      "\n",
      "\n",
      "Modelos ensambladores:\n",
      "\n",
      "\n",
      "Stacking\n",
      "\n",
      "\n",
      "\n",
      "====== Optimizando ridge ======\n",
      "Mejores parámetros: {'modelo__alpha': 10}\n",
      "[VALIDACIÓN] MAE=0.12, RMSE=0.14, MAPE=41.25%\n",
      "[TEST] MAE=0.12, RMSE=0.14, MAPE=39.59%\n",
      "\n",
      "====== Optimizando rf ======\n",
      "Mejores parámetros: {'modelo__max_depth': 10, 'modelo__n_estimators': 100}\n",
      "[VALIDACIÓN] MAE=0.00, RMSE=0.00, MAPE=0.00%\n",
      "[TEST] MAE=0.00, RMSE=0.00, MAPE=0.00%\n",
      "\n",
      "====== Optimizando xgb ======\n",
      "Mejores parámetros: {'modelo__learning_rate': 0.1, 'modelo__n_estimators': 400}\n",
      "[VALIDACIÓN] MAE=0.00, RMSE=0.00, MAPE=0.00%\n",
      "[TEST] MAE=0.00, RMSE=0.00, MAPE=0.00%\n",
      "[STACKING VALIDACIÓN] MAE=0.00, RMSE=0.00, MAPE=0.00%\n",
      "[STACKING TEST]       MAE=0.00, RMSE=0.00, MAPE=0.00%\n",
      "\n",
      "\n",
      "Blending\n",
      "\n",
      "\n",
      "\n",
      "====== Optimizando ridge ======\n",
      "Mejores parámetros: {'modelo__alpha': 10}\n",
      "[VALIDACIÓN] MAE=0.12, RMSE=0.14, MAPE=41.25%\n",
      "[TEST] MAE=0.12, RMSE=0.14, MAPE=39.59%\n",
      "\n",
      "====== Optimizando rf ======\n",
      "Mejores parámetros: {'modelo__max_depth': 10, 'modelo__n_estimators': 100}\n",
      "[VALIDACIÓN] MAE=0.00, RMSE=0.00, MAPE=0.00%\n",
      "[TEST] MAE=0.00, RMSE=0.00, MAPE=0.00%\n",
      "\n",
      "====== Optimizando xgb ======\n",
      "Mejores parámetros: {'modelo__learning_rate': 0.1, 'modelo__n_estimators': 400}\n",
      "[VALIDACIÓN] MAE=0.00, RMSE=0.00, MAPE=0.00%\n",
      "[TEST] MAE=0.00, RMSE=0.00, MAPE=0.00%\n",
      "[BLENDING VALIDACIÓN] MAE=0.00, RMSE=0.00, MAPE=0.00%\n",
      "[BLENDING TEST]       MAE=0.00, RMSE=0.00, MAPE=0.00%\n",
      "Modelo «lineal» guardado en ../models/CAC_source_30/lineal.pkl\n",
      "Modelo «estocastico» guardado en ../models/CAC_source_30/estocastico.pkl\n",
      "Modelo «ridge» guardado en ../models/CAC_source_30/ridge.pkl\n",
      "Modelo «rf» guardado en ../models/CAC_source_30/rf.pkl\n",
      "Modelo «xgb» guardado en ../models/CAC_source_30/xgb.pkl\n",
      "Modelo «lgbm» guardado en ../models/CAC_source_30/lgbm.pkl\n",
      "Modelo «catboost» guardado en ../models/CAC_source_30/catboost.pkl\n",
      "Modelo «stacking» guardado en ../models/CAC_source_30/stacking.pkl\n",
      "Modelo «blending» guardado en ../models/CAC_source_30/blending.pkl\n"
     ]
    }
   ],
   "source": [
    "# Entrenar y guardar LTV\n",
    "print(\"ENTRENAMIENTO Y EVALUACION DE LTV\")\n",
    "modelos_ltv, evaluaciones_ltv = ejecutar_modelos(df, target_col='LTV_180')\n",
    "guardar_modelos_y_resultados(modelos_ltv, evaluaciones_ltv, target_name='LTV_180')\n",
    "\n",
    "# Entrenar y guardar CAC\n",
    "print(\"ENTRENAMIENTO Y EVALUACION DE CAC\")\n",
    "modelos_cac, evaluaciones_cac = ejecutar_modelos(df, target_col='CAC_source_30')\n",
    "guardar_modelos_y_resultados(modelos_cac, evaluaciones_cac, target_name='CAC_source_30')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "82e48a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Modelos (LTV_180)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lgbm</th>\n",
       "      <td>1.665485e+00</td>\n",
       "      <td>2.223162e+01</td>\n",
       "      <td>3.905376e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stacking</th>\n",
       "      <td>8.073899e-01</td>\n",
       "      <td>1.887428e+00</td>\n",
       "      <td>4.232686e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>7.270041e-01</td>\n",
       "      <td>6.553983e+00</td>\n",
       "      <td>4.504200e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ridge</th>\n",
       "      <td>8.531102e-01</td>\n",
       "      <td>2.007907e+00</td>\n",
       "      <td>4.875546e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lineal</th>\n",
       "      <td>8.531092e-01</td>\n",
       "      <td>2.007905e+00</td>\n",
       "      <td>4.875902e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blending</th>\n",
       "      <td>9.610361e-01</td>\n",
       "      <td>3.179944e+00</td>\n",
       "      <td>5.029398e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>catboost</th>\n",
       "      <td>1.124426e+00</td>\n",
       "      <td>1.436599e+01</td>\n",
       "      <td>5.778491e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>7.969796e-01</td>\n",
       "      <td>3.665115e+00</td>\n",
       "      <td>6.833408e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>estocastico</th>\n",
       "      <td>1.098345e+08</td>\n",
       "      <td>5.458513e+08</td>\n",
       "      <td>5.266889e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            MAE          RMSE          MAPE\n",
       "Modelos (LTV_180)                                          \n",
       "lgbm               1.665485e+00  2.223162e+01  3.905376e+01\n",
       "stacking           8.073899e-01  1.887428e+00  4.232686e+01\n",
       "xgb                7.270041e-01  6.553983e+00  4.504200e+01\n",
       "ridge              8.531102e-01  2.007907e+00  4.875546e+01\n",
       "lineal             8.531092e-01  2.007905e+00  4.875902e+01\n",
       "blending           9.610361e-01  3.179944e+00  5.029398e+01\n",
       "catboost           1.124426e+00  1.436599e+01  5.778491e+01\n",
       "rf                 7.969796e-01  3.665115e+00  6.833408e+01\n",
       "estocastico        1.098345e+08  5.458513e+08  5.266889e+09"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Modelos (CAC_source_30)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>blending</th>\n",
       "      <td>4.533731e-15</td>\n",
       "      <td>5.020784e-15</td>\n",
       "      <td>1.504793e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>4.987834e-15</td>\n",
       "      <td>5.683308e-15</td>\n",
       "      <td>1.628510e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stacking</th>\n",
       "      <td>6.603138e-14</td>\n",
       "      <td>6.614859e-14</td>\n",
       "      <td>2.311970e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgbm</th>\n",
       "      <td>3.377672e-06</td>\n",
       "      <td>3.970301e-06</td>\n",
       "      <td>1.132081e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>9.397128e-06</td>\n",
       "      <td>1.095531e-05</td>\n",
       "      <td>3.460200e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>catboost</th>\n",
       "      <td>3.005680e-04</td>\n",
       "      <td>3.340685e-04</td>\n",
       "      <td>1.136214e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ridge</th>\n",
       "      <td>1.174255e-01</td>\n",
       "      <td>1.423042e-01</td>\n",
       "      <td>3.959448e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lineal</th>\n",
       "      <td>1.174243e-01</td>\n",
       "      <td>1.423053e-01</td>\n",
       "      <td>3.959456e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>estocastico</th>\n",
       "      <td>1.185008e-01</td>\n",
       "      <td>1.424571e-01</td>\n",
       "      <td>4.007841e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  MAE          RMSE          MAPE\n",
       "Modelos (CAC_source_30)                                          \n",
       "blending                 4.533731e-15  5.020784e-15  1.504793e-12\n",
       "rf                       4.987834e-15  5.683308e-15  1.628510e-12\n",
       "stacking                 6.603138e-14  6.614859e-14  2.311970e-11\n",
       "lgbm                     3.377672e-06  3.970301e-06  1.132081e-03\n",
       "xgb                      9.397128e-06  1.095531e-05  3.460200e-03\n",
       "catboost                 3.005680e-04  3.340685e-04  1.136214e-01\n",
       "ridge                    1.174255e-01  1.423042e-01  3.959448e+01\n",
       "lineal                   1.174243e-01  1.423053e-01  3.959456e+01\n",
       "estocastico              1.185008e-01  1.424571e-01  4.007841e+01"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Para LTV\n",
    "res_ltv = mostrar_resultados(evaluaciones_ltv, \"LTV_180\")\n",
    "\n",
    "# Para CAC\n",
    "res_cac = mostrar_resultados(evaluaciones_cac, \"CAC_source_30\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
